# -*- coding: utf-8 -*-
"""Analysing3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UQLOBetbSMPpoaiQrJd_SqdMmuI00_OP
"""

from google.colab import drive
drive.mount('/content/drive')
# Example: Accessing a file in your 'My Drive' folder
file_path1 = '/content/drive/My Drive/Project/Quantics/Dataset/email_opened_table.csv'
filepath2= '/content/drive/My Drive/Project/Quantics/Dataset/email_table.csv'
filepath3='/content/drive/My Drive/Project/Quantics/Dataset/link_clicked_table.csv' # Replace with your file's path# Assuming it's a CSV file, adjust as needed

import pandas as pd  # For data manipulation and analysis
import numpy as np  # For numerical computations
import matplotlib.pyplot as plt  # For creating visualizations
import seaborn as sns  # For statistical data visualization
import sklearn #scikit-learn is aliased as sklearn in python 3. In python2, the library is just sklearn

df = pd.read_csv(filepath2)
df_emailopened= pd.read_csv(file_path1)
df_linkopened=pd.read_csv(filepath3)
df.head()

df['Email opened'] = df['email_id'].isin(df_emailopened['email_id']).map({True: 'Yes', False: 'No'})

df['Link opened'] = df['email_id'].isin(df_linkopened['email_id']).map({True: 'Yes', False: 'No'})

df_emailopened.head()

df.head()

# prompt: check for duplicate values

# Check for duplicate email IDs in the main DataFrame
duplicate_emails = df[df.duplicated(subset=['email_id'], keep=False)]

if not duplicate_emails.empty:
  print("Duplicate email IDs found:")
  print(duplicate_emails)
else:
  print("No duplicate email IDs found.")

# Check for duplicate email IDs in the 'email_opened' DataFrame
duplicate_opened_emails = df_emailopened[df_emailopened.duplicated(subset=['email_id'], keep=False)]

if not duplicate_opened_emails.empty:
  print("\nDuplicate email IDs found in 'email_opened' DataFrame:")
  print(duplicate_opened_emails)
else:
  print("\nNo duplicate email IDs found in 'email_opened' DataFrame.")

# Check for duplicate email IDs in the 'link_opened' DataFrame
duplicate_link_emails = df_linkopened[df_linkopened.duplicated(subset=['email_id'], keep=False)]

if not duplicate_link_emails.empty:
    print("\nDuplicate email IDs found in 'link_opened' DataFrame:")
    print(duplicate_link_emails)
else:
    print("\nNo duplicate email IDs found in 'link_opened' DataFrame.")

# prompt: find all the unique elements in the column user_past_purchase

unique_users = df['user_past_purchases'].unique()
unique_users

# prompt: try and predict what is the best case situation, like the optimal value for all columns for the max chances of link being opened the various columns are email_text	email_version	hour	weekday	user_country	user_past_purchases

# Assuming 'df' is your combined DataFrame with 'Link opened' column

# Group by all relevant columns and calculate the link open rate
link_open_rates = df.groupby(['email_text', 'email_version', 'hour', 'weekday', 'user_country', 'user_past_purchases'])['Link opened'].value_counts(normalize=True).unstack()

# Find the combination with the highest "Yes" (link opened) rate
best_combination = link_open_rates['Yes'].idxmax()

print("The optimal combination for maximum link open probability is:")
best_combination

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, roc_curve
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

# Features and target
features = ['email_text', 'email_version', 'hour', 'weekday', 'user_country', 'user_past_purchases', 'Email opened']
target = 'Link opened'

# Prepare X and y
X = df[features].copy()
y = df[target].copy()

# Fix string columns to numeric
X['Email opened'] = X['Email opened'].map({'Yes': 1, 'No': 0})
y = y.map({'Yes': 1, 'No': 0}) if y.dtype == 'O' else y
X['user_past_purchases'] = pd.to_numeric(X['user_past_purchases'], errors='coerce')

# Handle any missing values if necessary
X = X.fillna(0)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define preprocessors
categorical_cols = ['email_text', 'email_version', 'weekday', 'user_country']
numerical_cols = ['hour', 'user_past_purchases', 'Email opened']

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', StandardScaler(), numerical_cols)
    ]
)

# Apply preprocessing to training data
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# SMOTE to handle imbalance
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train_processed, y_train)

# Train model
model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
model.fit(X_resampled, y_resampled)

# Predict
y_pred = model.predict(X_test_processed)
y_proba = model.predict_proba(X_test_processed)[:, 1]

# Evaluation
print("ROC AUC Score:", roc_auc_score(y_test, y_proba))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
plt.figure(figsize=(8,6))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc_score(y_test, y_proba):.4f}")
plt.plot([0,1], [0,1], 'k--', label="Random")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid(True)
plt.show()

# prompt: find the conversion rate and the open rate

# Calculate the conversion rate
total_emails = len(df)
converted_users = len(df[df['Link opened'] == 'Yes'])
conversion_rate = (converted_users / total_emails) * 100

print(f"Conversion Rate: {conversion_rate:.2f}%")

# Calculate the open rate
opened_emails = len(df[df['Email opened'] == 'Yes'])
open_rate = (opened_emails / total_emails) * 100

print(f"Open Rate: {open_rate:.2f}%")

# prompt: can you predict using models what is the best way to send the mails

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Assuming 'df' is your combined DataFrame with 'Email opened', 'Link opened', and relevant features

# Feature Engineering (example, adapt to your actual features)
# Example features:  'user_past_purchases', 'email_subject_length', 'day_of_week', 'time_of_day'
#  You need to create these columns based on your data
#  The code below is a placeholder

# Convert categorical features to numerical using one-hot encoding
df = pd.get_dummies(df, columns=['Email opened','Link opened'], drop_first=True) # Example: One-hot encode 'Email opened'


# Define features (X) and target variable (y)
# Replace with your actual features
features = ['user_past_purchases'] # Add other relevant features
X = df[features]
y = df['Link opened_Yes'] # Predicting link clicks

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Initialize and train a model (RandomForestClassifier as an example)
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))


# Example prediction (replace with your actual input data)
#new_data = pd.DataFrame({'user_past_purchases':[5]}) # Example new datapoint
#prediction = model.predict(new_data)
#print(f"Prediction: {prediction}") # 1 = Link Opened, 0 = Link Not Opened



#Further Improvements

# 1. Feature Engineering:  Create more relevant features from your data. Examples:
#   - Email subject length/keywords
#   - Time of day email was sent
#   - Day of the week email was sent
#   - User demographics (if available)
#   - Email content features (sentiment analysis, number of images/links, etc.)
#   - User engagement history (frequency of opens, clicks, etc.)
#   - Segmentation based on user behaviour or preferences
# 2. Model Selection: Experiment with other suitable models. Logistic Regression or gradient boosted models might work well.
# 3. Hyperparameter Tuning:  Use techniques like GridSearchCV or RandomizedSearchCV to find the optimal settings for your chosen model.
# 4. Cross-validation:  Employ k-fold cross-validation for more robust model evaluation.
# 5. Handling Imbalance (if applicable): Check for class imbalance in your data (link clicks vs. no clicks) and use techniques like SMOTE or class weights if needed.
# 6. Data Cleaning: Ensure your data is free from errors, missing values are properly addressed, and any inconsistencies are corrected.

# prompt: classify all the values in the user_past_purchase column if New → 0 purchases
# Low → 1–3 purchases
# Mid → 4–10 purchases
# High → more than 10

def classify_purchases(purchases):
    if purchases == 'New':
        return 0
    elif purchases == 'Low':
        return 1
    elif purchases == 'Mid':
        return 2
    elif purchases == 'High':
        return 3
    else:
        try:
            purchases = int(purchases)
            if 1 <= purchases <= 3:
                return 1
            elif 4 <= purchases <= 10:
                return 2
            elif purchases > 10:
                return 3
            else:
                return 0 # Handle cases where purchases are 0 or negative.
        except (ValueError, TypeError):
            return 0 # Handle non-numeric inputs gracefully

# Apply the function to the 'user_past_purchases' column
df['purchase_category'] = df['user_past_purchases'].apply(classify_purchases)
df.head()

# prompt: create a plot of the purchase_category and the count of email opened (if email opened is Yes)

# Group the data by 'purchase_category' and count the occurrences where 'Email opened' is 'Yes'
email_opened_counts = df[df['Email opened'] == 'Yes'].groupby('purchase_category')['Email opened'].count()

# Create the plot
plt.figure(figsize=(10, 6))
sns.barplot(x=email_opened_counts.index, y=email_opened_counts.values)
plt.xlabel('Purchase Category')
plt.ylabel('Count of Email Opened')
plt.title('Email Opened Count by Purchase Category')
plt.show()

# prompt: plot a graph of purchase category and count of link opened (if link opened is yes)

# Group the data by 'purchase_category' and count the occurrences where 'Link opened' is 'Yes'
link_opened_counts = df[df['Link opened'] == 'Yes'].groupby('purchase_category')['Link opened'].count()

# Create the plot
plt.figure(figsize=(10, 6))
sns.barplot(x=link_opened_counts.index, y=link_opened_counts.values)
plt.xlabel('Purchase Category')
plt.ylabel('Count of Link Opened')
plt.title('Link Opened Count by Purchase Category')
plt.show()

# prompt: what is the value of count of link opened when purchase category is 0

# Access the value directly from the link_opened_counts Series
count_link_opened_purchase_0 = link_opened_counts.get(0, 0)

print(f"The count of links opened when the purchase category is 0 is: {count_link_opened_purchase_0}")

df.tail()

# prompt: create a new column where u put all short_email as 0 and long_email as 1 from the colum email_text (the values in the column are short_email and long_email)

# Create the new column 'email_type' based on 'email_text'
df['email_type'] = df['email_text'].apply(lambda x: 0 if x == 'short_email' else 1 if x == 'long_email' else -1)
df.head()

# prompt: create a new column from email_version, where if the value is personalized then put it as 1 otherwise 0

# Create the new column 'personalized' based on 'email_version'
df['personalized'] = df['email_version'].apply(lambda x: 1 if x == 'personalized' else 0)
df.head()

# prompt: find out the different values in user_country

unique_countries = df['user_country'].unique()
unique_countries

# prompt: for all the values in user_country, create a new column where US is 0 UK is 1 FR is 2 and ES is 3

def country_mapping(country):
    if country == 'US':
        return 0
    elif country == 'UK':
        return 1
    elif country == 'FR':
        return 2
    elif country == 'ES':
        return 3
    else:
        return -1  # Handle unknown countries

df['user_country_code'] = df['user_country'].apply(country_mapping)
df.head()

df.tail()

# prompt: ok now make a decision tree model where the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end
# also oversample the minority class which is that there are less cases of link opened being Yes

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from imblearn.over_sampling import RandomOverSampler

# Define features (X) and target (y)
features = ['purchase_category', 'email_type', 'personalized','hour', 'user_country_code']
target = 'Link opened'

X = df[features]
y = df[target]

# Convert categorical features to numerical using one-hot encoding
#X = pd.get_dummies(X, columns=['Email opened'], drop_first=True) # Example, adjust for other categorical columns as needed

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Oversample the minority class ('Yes' in 'Link opened')
oversampler = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)

# Initialize and train the decision tree classifier
dt_classifier = DecisionTreeClassifier(random_state=42) # You can add hyperparameters here, e.g., max_depth
dt_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = dt_classifier.predict(X_test)

# Evaluate the model using a confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dt_classifier.classes_)
disp.plot()
plt.show()

# prompt: ok now make a random forest where the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class which is that there are less cases of link opened being Yes

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Initialize and train the Random Forest classifier
rf_classifier = RandomForestClassifier(random_state=42)  # You can add hyperparameters here
rf_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = rf_classifier.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_classifier.classes_)
disp.plot()
plt.show()

# prompt: ok now make a gradient boosting where the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class which is that there are less cases of link opened being Yes

from sklearn.ensemble import GradientBoostingClassifier

# Initialize and train the Gradient Boosting classifier
gb_classifier = GradientBoostingClassifier(random_state=42)  # You can add hyperparameters here
gb_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = gb_classifier.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=gb_classifier.classes_)
disp.plot()
plt.show()

# prompt: ok now make a knn model where the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class which is that there are less cases of link opened being Yes

from sklearn.neighbors import KNeighborsClassifier

# Initialize and train the KNN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5) # You can adjust the number of neighbors
knn_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = knn_classifier.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn_classifier.classes_)
disp.plot()
plt.show()

# prompt: ok now make aSVMwhere the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class which is that there are less cases of link opened being Yes

from sklearn.svm import SVC

# Initialize and train the SVM classifier
svm_classifier = SVC(random_state=42)  # You can add hyperparameters here
svm_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = svm_classifier.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=svm_classifier.classes_)
disp.plot()
plt.show()

# prompt: ok now make a knn model where the feature variables are purchase_category, email_type, email opened, personalized, hour, weekday, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class where link opened is Yes
# also the weekday column is having values like Monday, tuesday etc so deal with that

# Convert 'weekday' to numerical representation
weekday_mapping = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6}
df['weekday'] = df['weekday'].map(weekday_mapping)

# Define features (X) and target (y)
features = ['purchase_category', 'email_type', 'Email opened', 'personalized', 'hour', 'weekday', 'user_country_code']
target = 'Link opened'

X = df[features]
y = df[target]

# Convert categorical features to numerical using one-hot encoding
X = pd.get_dummies(X, columns=['Email opened'], drop_first=True)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Oversample the minority class ('Yes' in 'Link opened')
oversampler = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)

# Initialize and train the KNN classifier
knn_classifier = KNeighborsClassifier(n_neighbors=5) # You can adjust the number of neighbors
knn_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = knn_classifier.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn_classifier.classes_)
disp.plot()
plt.show()

# prompt: ok now make a Mlp classifier model where the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class which is that there are less cases of link opened being Yes

from sklearn.neural_network import MLPClassifier

# Initialize and train the MLP classifier
mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42) # You can adjust hyperparameters
mlp_classifier.fit(X_train_resampled, y_train_resampled)

# Make predictions on the test set
y_pred = mlp_classifier.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Display the confusion matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mlp_classifier.classes_)
disp.plot()
plt.show()

# prompt: ok now make aTensorFlow/Keras-based Deep Neural Network where the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class which is that there are less cases of link opened being Yes

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score
import matplotlib.pyplot as plt
import numpy as np

# Assuming X_train_resampled, y_train_resampled, X_test, y_test are defined from the previous code

# Convert y to numerical labels
y_train_resampled_num = np.where(y_train_resampled == 'Yes', 1, 0)
y_test_num = np.where(y_test == 'Yes', 1, 0)

# Define the model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(X_train_resampled, y_train_resampled_num, epochs=10, batch_size=32)  # Adjust epochs and batch_size as needed

# Make predictions
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int) # Convert probabilities to binary predictions


# Evaluate the model
print("Accuracy:", accuracy_score(y_test_num, y_pred))
print("\nClassification Report:\n", classification_report(y_test_num, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test_num, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])
disp.plot()
plt.show()

# prompt: ok now make aTensorFlow/Keras-based Deep Neural Network where the feature variables are purchase_category, email_type, personalized, Email opened and user_country code and the target variable is Link opened, also gi ve a confusion matrix at the end, and also accuracy and all the reports
# also oversample the minority class which is that there are less cases of link opened being Yes

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd # Import pandas for data manipulation

# Assuming X_train_resampled, y_train_resampled, X_test, y_test are defined from the previous code

# Convert y to numerical labels
y_train_resampled_num = np.where(y_train_resampled == 'Yes', 1, 0)
y_test_num = np.where(y_test == 'Yes', 1, 0)

# Convert categorical features to numerical using one-hot encoding in X_train_resampled and X_test
X_train_resampled = pd.get_dummies(X_train_resampled, columns=['purchase_category', 'email_type', 'personalized', 'user_country_code'])
X_test = pd.get_dummies(X_test, columns=['purchase_category', 'email_type', 'personalized', 'user_country_code'])


# Align columns between training and testing data
# Get missing columns in training data
missing_cols_train = set(X_test.columns) - set(X_train_resampled.columns)
# Add a missing column in training set with default value equal to 0
for c in missing_cols_train:
    X_train_resampled[c] = 0
# Get missing columns in testing data
missing_cols_test = set(X_train_resampled.columns) - set(X_test.columns)
# Add a missing column in testing set with default value equal to 0
for c in missing_cols_test:
    X_test[c] = 0
# Ensure the order of column in the test set is the same as in the train set
X_test = X_test[X_train_resampled.columns]

# Define the model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(X_train_resampled, y_train_resampled_num, epochs=0, batch_size=32)  # Adjust epochs and batch_size as needed

# Make predictions
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int) # Convert probabilities to binary predictions


# Evaluate the model
print("Accuracy:", accuracy_score(y_test_num, y_pred))
print("\nClassification Report:\n", classification_report(y_test_num, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test_num, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])
disp.plot()
plt.show()

# prompt: use apriori to find interesting relations in my data

!pip install mlxtend

import pandas as pd
from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules

# Assuming your data is in a pandas DataFrame called 'df'
# and you've already preprocessed it (e.g., one-hot encoding)

# Example: Create a sample dataset
# Replace this with your actual data loading and preprocessing

data = {'TransactionID': [1, 2, 3, 4, 5],
        'Item1': [1, 0, 1, 1, 0],
        'Item2': [1, 1, 0, 1, 0],
        'Item3': [0, 1, 1, 0, 1]}
df_apriori = pd.DataFrame(data)
# Convert to appropriate format for Apriori
df_apriori = df_apriori.drop('TransactionID', axis=1)

# Apply Apriori algorithm
frequent_itemsets = apriori(df_apriori, min_support=0.2, use_colnames=True)

# Generate association rules
rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)

rules

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd # Import pandas for data manipulation

# Assuming X_train_resampled, y_train_resampled, X_test, y_test are defined from the previous code

# Convert y to numerical labels
y_train_resampled_num = np.where(y_train_resampled == 'Yes', 1, 0)
y_test_num = np.where(y_test == 'Yes', 1, 0)

# Define features (X) and target (y) - THIS IS THE ADDED CODE
features = ['purchase_category', 'email_type', 'Email opened', 'personalized', 'hour', 'weekday', 'user_country_code']
target = 'Link opened'

X = df[features] # Recreate X from the original dataframe
y = df[target]


# Convert categorical features to numerical using one-hot encoding
X = pd.get_dummies(X, columns=['Email opened'], drop_first=True)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Oversample the minority class ('Yes' in 'Link opened')
oversampler = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)


# Convert categorical features to numerical using one-hot encoding in X_train_resampled and X_test
X_train_resampled = pd.get_dummies(X_train_resampled, columns=['purchase_category', 'email_type', 'personalized', 'user_country_code'])
X_test = pd.get_dummies(X_test, columns=['purchase_category', 'email_type', 'personalized', 'user_country_code'])


# Align columns between training and testing data
# Get missing columns in training data
missing_cols_train = set(X_test.columns) - set(X_train_resampled.columns)
# Add a missing column in training set with default value equal to 0
for c in missing_cols_train:
    X_train_resampled[c] = 0
# Get missing columns in testing data
missing_cols_test = set(X_train_resampled.columns) - set(X_test.columns)
# Add a missing column in testing set with default value equal to 0
for c in missing_cols_test:
    X_test[c] = 0
# Ensure the order of column in the test set is the same as in the train set
X_test = X_test[X_train_resampled.columns]

# Define the model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(X_train_resampled, y_train_resampled_num, epochs=10, batch_size=32)  # Adjust epochs and batch_size as needed

# Make predictions
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int) # Convert probabilities to binary predictions


# Evaluate the model
print("Accuracy:", accuracy_score(y_test_num, y_pred))
print("\nClassification Report:\n", classification_report(y_test_num, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test_num, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])
disp.plot()
plt.show()

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd # Import pandas for data manipulation

# Assuming X_train_resampled, y_train_resampled, X_test, y_test are defined from the previous code

# Convert y to numerical labels
y_train_resampled_num = np.where(y_train_resampled == 'Yes', 1, 0)
y_test_num = np.where(y_test == 'Yes', 1, 0)

# Define features (X) and target (y) - THIS IS THE ADDED CODE
features = ['purchase_category', 'email_type', 'Email opened', 'personalized', 'hour', 'weekday', 'user_country_code']
target = 'Link opened'

X = df[features] # Recreate X from the original dataframe
y = df[target]


# Convert categorical features to numerical using one-hot encoding
X = pd.get_dummies(X, columns=['Email opened'], drop_first=True)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Oversample the minority class ('Yes' in 'Link opened')
oversampler = RandomOverSampler(random_state=42)
X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)


# Convert categorical features to numerical using one-hot encoding in X_train_resampled and X_test
X_train_resampled = pd.get_dummies(X_train_resampled, columns=['purchase_category', 'email_type', 'personalized', 'user_country_code'])
X_test = pd.get_dummies(X_test, columns=['purchase_category', 'email_type', 'personalized', 'user_country_code'])


# Align columns between training and testing data
# Get missing columns in training data
missing_cols_train = set(X_test.columns) - set(X_train_resampled.columns)
# Add a missing column in training set with default value equal to 0
for c in missing_cols_train:
    X_train_resampled[c] = 0
# Get missing columns in testing data
missing_cols_test = set(X_train_resampled.columns) - set(X_test.columns)
# Add a missing column in testing set with default value equal to 0
for c in missing_cols_test:
    X_test[c] = 0
# Ensure the order of column in the test set is the same as in the train set
X_test = X_test[X_train_resampled.columns]

# Convert the dataframes to float32 - THIS IS THE ADDED CODE
X_train_resampled = X_train_resampled.astype(np.float32)
X_test = X_test.astype(np.float32)

# Define the model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(X_train_resampled.shape[1],)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(X_train_resampled, y_train_resampled_num, epochs=20, batch_size=32)  # Adjust epochs and batch_size as needed

# Make predictions
y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype(int) # Convert probabilities to binary predictions


# Evaluate the model
print("Accuracy:", accuracy_score(y_test_num, y_pred))
print("\nClassification Report:\n", classification_report(y_test_num, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test_num, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])
disp.plot()
plt.show()

# prompt: can you output the new dataframe i made into a downloadable csv the dataframe is called df

from google.colab import files
df.to_csv('df_output.csv', encoding = 'utf-8-sig')
files.download('df_output.csv')

